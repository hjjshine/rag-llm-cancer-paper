#utils/evaluation.py
import sys
import os
script_dir = os.getcwd()
root_dir = os.path.join(os.path.dirname(os.path.abspath(script_dir)))
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(script_dir))))

from sklearn.metrics import precision_score, recall_score, f1_score
from utils.io import load_object
import pandas as pd
import re

# Load brand-generic name mapped dictionary and prompt-groundtruth (generic) mapped dictionary
drug_names_mapping_dict=load_object(filename=os.path.join(root_dir,'data/fda_drug_names_mapping_dict.pkl'))

# Extract ground-truth generic and brand names
all_generic_names_set=set()
for lst in drug_names_mapping_dict.values():
    for name in lst:
        all_generic_names_set.add(frozenset(name))

# Function to extract drug names
def extract_drug_names(drug_lines):
    pattern = r'"drug names?":\s?(?:\[(.*?)\]|"(.*?)"|([^"\[\]]+))'
    cleaned_drug_list = []
    for line in drug_lines:
        match = re.search(pattern, line)
        if match:
            drug_string = next(filter(None, match.groups())) # Extract the first non-empty capturing group
            drug_string = re.sub(r'\s?\([^)]*\)', '', drug_string) # Remove any text within parentheses
            drugs = [drug.strip().strip('"').replace('Â®', '') for drug in re.split(r'\s*\+\s*|\s*,\s*', drug_string)] # Split by `+` or `,` and clean spaces & quotes
            cleaned_drug_list.append(set(drugs))
    return(cleaned_drug_list)

# Function to evaluate predicted drugs from synthetic queries
def calc_eval_metrics(
    output_test_ls: list[str], 
    query_ls: list[str], 
    prompt_groundtruth_dict: dict[str, list]
    ) -> dict:
    """
    Evaluate predicted drug from LLM.
    
    Arguments: 
        output_test_ls (list): List of full output generated by LLM.
        query_ls (list): List of input prompts.
        prompt_groundtruth_dict (dict): Dictionary of input prompts and matching ground-truth drugs.
    
    """
    exact_match_acc, partial_match_acc = [], []
    precision_ls, recall_ls, f1_ls, specificity_ls = [], [], [], []
    pred_drugs_generic_set_ls = []
    true_drugs_generic_set_ls = []
    
    for i, output in enumerate(output_test_ls):
        
        # Extract drug name lines
        s_split=output.split("\n") # Split each line
        drug_lines=[line.lower() for line in s_split if "Drug Name" in line] # Extract relevant lines
        
        # Create a set of predicted individual drugs
        pred_drugs_names_set = extract_drug_names(drug_lines)
        
        # Convert brand names to generic names if there are matching brand names, otherwise just append
        pred_drugs_generic_list=[]
        for subset in pred_drugs_names_set:
            normalized_subset_list=[]
            if all(drug not in drug_names_mapping_dict for drug in subset): # if all drugs are not a brand name in our mapping dict
                normalized_subset_list.extend([subset])
            else:
                for drug in subset:
                    if drug in drug_names_mapping_dict:
                        generic_names=drug_names_mapping_dict[drug]
                        normalized_subset_list.extend(generic_names) 
                    else:
                        normalized_subset_list.extend([{drug}])
            pred_drugs_generic_list.append(normalized_subset_list)
        
        # Convert the list of generic names to unique frozensets 
        pred_drugs_generic_set=set()
        for lst in pred_drugs_generic_list:
            if len(lst) == 1:
                pred_drugs_generic_set.add(frozenset(*lst))
            else:
                for subset in lst:
                    pred_drugs_generic_set.add(frozenset(subset))
        pred_drugs_generic_set_ls.append(pred_drugs_generic_set)
        
        # Convert the list of ground-truth generic names to unique frozensets
        true_drugs_generic_set = {frozenset(_set) for _set in prompt_groundtruth_dict[query_ls[i]]}
        true_drugs_generic_set_ls.append(true_drugs_generic_set)
        
        # Cases with ground-truth therapies
        if len(true_drugs_generic_set) != 0:
            
            # Compute exact match accuracy (if all true drugs are in the predicted drug output)
            exact_match_acc.append(all(subset in pred_drugs_generic_set for subset in true_drugs_generic_set))
            
            # Compute partial match accuracy (if one or more true drugs are in the predicted drug output)
            partial_match_acc.append(len(pred_drugs_generic_set & true_drugs_generic_set) > 0)
            
            # All possible FDA-approved drugs
            all_drugs_set = true_drugs_generic_set | pred_drugs_generic_set | all_generic_names_set
            
            # Calculate true positive, false positive, false negative, true negative
            tp = len(pred_drugs_generic_set.intersection(true_drugs_generic_set))  
            fp = len(pred_drugs_generic_set - true_drugs_generic_set)  
            fn = len(true_drugs_generic_set - pred_drugs_generic_set)  
            tn = len(all_drugs_set - true_drugs_generic_set - pred_drugs_generic_set)  
            
            # Calculate precision, recall, and F1 scores
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  
            precision_ls.append(precision)
            recall_ls.append(recall)
            f1_ls.append(f1)
            specificity_ls.append(specificity) 
        
        # Cases with no ground-truth therapies (no FDA-approved drugs available)
        else:
            partial_match_acc.append(True if not true_drugs_generic_set and not pred_drugs_generic_set else False) 
            exact_match_acc.append(True if not true_drugs_generic_set and not pred_drugs_generic_set else False) 
            precision_ls.append(None)
            recall_ls.append(None)
            f1_ls.append(None)
            specificity_ls.append(None)

    def filtered_res(lst):
            filtered_res = [x for x in lst if x is not None]  
            return(filtered_res)

    avg_exact_match_acc=sum(x is True for x in exact_match_acc)/len(exact_match_acc)
    avg_partial_match_acc=sum(x is True for x in partial_match_acc)/len(partial_match_acc)
    filtered_precision=filtered_res(precision_ls)
    filtered_recall=filtered_res(recall_ls)
    filtered_f1=filtered_res(f1_ls)
    filtered_specificity=filtered_res(specificity_ls)
    avg_precision=sum(filtered_precision)/len(filtered_precision)
    avg_recall=sum(filtered_recall)/len(filtered_recall)
    avg_f1=sum(filtered_f1)/len(filtered_f1)
    avg_specificity=sum(filtered_specificity)/len(filtered_specificity)

    result={
        'avg_exact_match_acc':avg_exact_match_acc,
        'avg_partial_match_acc':avg_partial_match_acc,
        'avg_precision':avg_precision,
        'avg_recall':avg_recall,
        'avg_f1':avg_f1,
        'avg_specificity':avg_specificity,
        'exact_match_acc':exact_match_acc,
        'partial_match_acc':partial_match_acc,
        'precision_ls':precision_ls,
        'recall_ls':recall_ls,
        'f1_ls':f1_ls,
        'specificity_ls':specificity_ls,
        'pred_drugs_generic_set_ls':pred_drugs_generic_set_ls,
        'true_drugs_generic_set_ls':true_drugs_generic_set_ls
    }
    
    return(result)
